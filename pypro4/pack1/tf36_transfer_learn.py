# -*- coding: utf-8 -*-
"""tf36_transfer_learn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IVlqCd6XxRTfHBGrMsquR7LJHo0jkXL6
"""

# 전이학습 : 이미 만들어진 모델의 일부를 재학습해서 내가 원하는 형태의 모델을 생성
# 사전훈련된 모델의 마지막 완전 연결층 부분만 새로 작성
# 미세조정 : 사전훈련된 모델의 합성곱층 마지막 일부를 재학습
# 이미 훈련된 개, 고양이 분류 모델 MobileNetV2을 사용!

# tensorflow dataset 읽기
# !pip install tensorflow-datasets

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_datasets as tfds
setattr(tfds.image_classification.cats_vs_dogs, '_URL',"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip")

(raw_train, raw_vali, raw_test), metadata = tfds.load('cats_vs_dogs', 
                                                      split=['train[:80%]','train[80%:90%]','train[90%:]'],
                                                      with_info=True, as_supervised=True)
print(raw_train)
print(raw_vali)
print(raw_test)

get_label_name = metadata.features['label'].int2str

for image, label in raw_train.take(2):
    plt.figure()
    plt.imshow(image)
    plt.title(get_label_name(label))
    plt.show()

from tensorflow.python.ops.gen_array_ops import tensor_scatter_update
# 이미지 조정
IMG_SIZE = 160

# 전이학습 대상 모델은 MobileNetV2
def format_ex(image, label):
    image = tf.cast(image, tf.float32)
    image = (image / 127.5) - 1
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    return image, label

train = raw_train.map(format_ex)
validation = raw_vali.map(format_ex)
test = raw_test.map(format_ex)

# 이미지 셔플링
BATCH_SIZE = 32
SUFFLE_BUFFER_SIZE = 1000

train_batches = train.shuffle(SUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
validation_batches = validation.batch(BATCH_SIZE)
test_batches = test.batch(BATCH_SIZE)

for image_batch, label_batch in train_batches.take(1):
    pass

print(image_batch.shape) #(32, 160, 160, 3)

# base model : 구글에서 개발한 MobileNetV2
IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')

feature_batch = base_model(image_batch)
print(feature_batch.shape) # (32, 5, 5, 1280)

# 계층 동결
base_model.trainable = False # 학습x
print(base_model.summary()) # MobileNetV2 확인

# 분류 모델링 : 전이학습 진행
global_average_layer = tf.keras.layers.GlobalAveragePooling2D() # AveragePoioling2D 보다 더 급격하게 feature의 수를 줄임
# Flatten이 일어나기 전후에 합성곱층에 적용하는 방식으로 각 특성 맵의 평균값을 추출해 벡터 생성
feature_batch_average = global_average_layer(feature_batch)
print(feature_batch_average.shape) #(32, 1280)

prediction_layer = tf.keras.layers.Dense(1)
prediction_feature = prediction_layer(feature_batch_average)
print(prediction_feature.shape) # (32, 1)

model = tf.keras.Sequential([
    base_model,
    global_average_layer,
    prediction_layer
])

base_learning_rate = 0.0001
model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

print(model.summary())

# 학습 전 모델 성능
validation_steps = 20
loss0, acc0 = model.evaluate(validation_batches, steps=validation_steps)
print('initial loss:{:.2f}'.format(loss0))
print('initial acc:{:.2f}'.format(acc0))

# 모델 학습
initial_epochs = 10
history = model.fit(train_batches, epochs=initial_epochs, validation_data=validation_batches)

# 시각화 
acc = history.history['accuracy']
val_acc =  history.history['val_accuracy']
loss = history.history['loss']
val_loss =  history.history['val_loss']

plt.figure(figsize=(8,8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='train acc')
plt.plot(val_acc, label='val_acc')
plt.legend()
plt.ylabel('acc')

plt.subplot(2, 1, 2)
plt.plot(loss, label='train loss')
plt.plot(val_loss, label='val_loss')
plt.legend()
plt.ylabel('loss')

plt.show()